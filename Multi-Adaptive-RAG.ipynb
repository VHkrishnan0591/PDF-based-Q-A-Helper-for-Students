{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ee24409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# All Necessary Libraries\n",
    "\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import Annotated\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import List, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6fdfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  4.61it/s]\n",
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  5.24it/s]\n",
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of documents after loading 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the datasource\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs =[]\n",
    "for url in urls:\n",
    "    loader = WebBaseLoader(web_paths=[url])\n",
    "    async for doc in loader.alazy_load():\n",
    "        docs.append(doc)\n",
    "print(\"The length of documents after loading\",len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da83a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of documents after loading 184\n"
     ]
    }
   ],
   "source": [
    "# Split the documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)\n",
    "print(\"The length of documents after loading\",len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ab7a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Generative AI\\Langchain\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['f70a6daf-4751-4904-9ae4-e21d4f5bc20d',\n",
       " '45ba1685-08a3-44d2-b535-e12d8bb4a6dd',\n",
       " '2713f8cf-da66-4a85-aead-e3534d819836',\n",
       " '2a4cdfc5-73ae-4672-8643-bc9cbddb7308',\n",
       " 'b35847f2-cd6b-4651-b4ee-1e29d0010819',\n",
       " '71aaacfd-bd40-42e2-9d79-7bcc0b1f3a93',\n",
       " 'd6e25106-8110-4c71-abed-7cca040b7c32',\n",
       " '7adf38e1-f688-444c-a2c6-2a5ccd366a13',\n",
       " 'd62b8adf-97a3-4405-87e8-6ee56ab6a9f4',\n",
       " 'ffed46d4-2dc3-4684-b37c-c08948807fa0',\n",
       " '47f1f306-62b1-4dc0-af7d-0b0001b50364',\n",
       " 'fdad7ae3-4b1b-41ad-9dc3-7d19c315d27a',\n",
       " '5b209f62-f2d2-4d72-a96e-c3a735c9d8a6',\n",
       " '99d7a1f7-91f2-4917-849d-25500f1ccf22',\n",
       " '6f8bd8b0-4dec-400a-9d6b-d1080d53a293',\n",
       " '46c4630d-b0be-4d54-8b5d-74e6b48f3758',\n",
       " 'd5b7119f-712c-4aac-b67f-519fa9ef2d1c',\n",
       " '9feaf202-1fed-455c-b8bf-ffcd4df56987',\n",
       " 'c8fdb88d-1a13-495b-8e0f-9aaa05f8434c',\n",
       " 'd5bf9eb6-1b22-4b17-9be1-48a7f28d8ce6',\n",
       " 'dc824527-2673-43af-ba4a-9dbb94b05947',\n",
       " '1db156db-d713-4675-877e-818892ad89d4',\n",
       " '17cc5933-6bc3-4be6-a7cc-c0f79d413b91',\n",
       " '29acdb0f-aa61-4a2c-810c-a06b97907807',\n",
       " '9cec7f7f-7abb-4d12-9d9f-ae780e9441fd',\n",
       " '15701c97-781d-4fb3-9565-70c3621184a8',\n",
       " 'f9a02c4c-5a02-4189-83b8-c5f5bb3f019c',\n",
       " '720ab08b-1b0d-4e38-89ac-7ba536ebe447',\n",
       " '47220726-d62c-4e41-aa66-0b81ad18fab9',\n",
       " '9ec74f97-3d9b-4c54-a9ce-062b34c3ee14',\n",
       " '94133e1a-75cb-427f-9eb9-b7d8562227dc',\n",
       " '849de3cf-cdd5-454f-b99f-4fe70ba08821',\n",
       " '0cb5d7d3-809f-4a99-bdf7-eedf37ac3681',\n",
       " '68f8d300-2a34-425d-954f-d6a7f0a17168',\n",
       " 'b391cac8-a202-4039-ad5e-31e21db42f4d',\n",
       " 'ef3aa12c-3ac8-4794-964b-baa50ec75b92',\n",
       " 'e1135975-0d1a-4b2b-b134-0d0ad3a19155',\n",
       " 'a425f40e-2a78-4cff-be44-77bd4590f3c9',\n",
       " '1073a73b-55ee-4091-b99d-596d8f8a354e',\n",
       " 'f37d7bd8-e4b4-4ce4-9a35-af2052efd70d',\n",
       " 'e5c9f6eb-55d0-434a-977e-4ffbf4543109',\n",
       " '4d44a34e-f1aa-4461-90ee-4b1f1374e872',\n",
       " 'af45a171-631e-4a16-bffb-cacbbdad1416',\n",
       " '35ab853b-e32c-4188-ba10-449eb77f6280',\n",
       " '71940fbf-8153-4528-bd9e-7917f9d1288a',\n",
       " 'c436940f-a31c-497b-ad8d-5e483c1305c5',\n",
       " 'fe57e989-6edc-43fb-a0df-9e3e295b2847',\n",
       " 'fa55ec62-07a9-4898-acba-1ccd57e34dbc',\n",
       " '579a4d28-a659-4ea4-8655-0248a63d59df',\n",
       " 'ae4ad9b5-4561-4019-a13b-cf1059452c14',\n",
       " '9cb46aa1-21f6-404b-9dd7-add412eafeff',\n",
       " 'b1ca513e-56dc-4f6c-9a28-bb171da854d4',\n",
       " '8abf0854-4d43-4a57-83f7-bfb3f785f85f',\n",
       " '4fc8ad93-011e-4595-8082-5a9a9ee141cc',\n",
       " '278a3a21-347b-4859-be5a-9f458a44772c',\n",
       " '93bff98a-3cd2-43a4-b43e-b69b035cbdbf',\n",
       " 'b01d8a1d-5c93-43c1-874f-9a94b5d91fc4',\n",
       " '308504fd-bb13-408c-9105-2afda8ccba3d',\n",
       " '2882a20f-a650-4a73-b129-b7500314c5cb',\n",
       " 'e1dd8587-3101-48fd-9759-1166b15da8ec',\n",
       " 'ff5a746c-c148-43b5-91ac-aa52c0b21eb1',\n",
       " '052ffd8c-26a6-432e-b573-ccd9d3470680',\n",
       " '97b3e221-8d55-4919-a7b9-aae31e023ff5',\n",
       " '21907682-9890-4dbb-bcdf-5280cc009800',\n",
       " 'a1f23312-bedb-4071-adb0-f00c64e5aecb',\n",
       " '67bf2ac6-0300-44c3-853e-3a2b41cfb9e5',\n",
       " 'fcb328af-b07a-4b00-affd-9466d9d911ed',\n",
       " '94da5b38-16af-49ba-9812-17c3346483b2',\n",
       " '98ef7588-03b6-4174-b3b5-ae9a16ee52d1',\n",
       " 'f187a7cc-da1d-40fa-998f-0bc7e13760e6',\n",
       " '3976b203-9c67-4cb0-b402-d0726ae405d2',\n",
       " 'f4fa6188-2464-499e-ab5e-d79e8be1350e',\n",
       " 'df873dca-adb9-4700-968d-e1efc6183592',\n",
       " 'd2edd249-ac1b-48da-825b-ef7332a7a5a9',\n",
       " 'fc3c3f58-3d9b-47f1-94e9-cbda549ed3b5',\n",
       " '3fb1fdb6-5f2b-444c-9126-df9e57f71e02',\n",
       " '006ea688-ba19-4133-bbaa-3e3781d17483',\n",
       " '0ab375a4-d2a7-40e5-858a-fffa974cf7ae',\n",
       " '0a9791de-c5dd-429e-8cb4-29e696642b90',\n",
       " '2d2e2ed8-da7e-436c-b424-acdaa68d2d62',\n",
       " 'c02a7d5e-0a1c-4f6c-a4fd-a32790e1fb74',\n",
       " 'c7aea748-9a16-4494-af10-3454fe82d289',\n",
       " '057c405a-c3a0-4835-bcf6-3c0705a26a56',\n",
       " '6895ed6f-ea60-45b1-8252-85aeb2a1c2aa',\n",
       " '77d55df7-4bff-481f-96cf-4cfde1837a9f',\n",
       " 'ac43b1a1-720a-4760-883a-5f04a95fb201',\n",
       " 'fb9eb092-33dc-4232-bebe-f43c5e60ce87',\n",
       " '558ec23d-e38e-48e2-87f1-346f81bba868',\n",
       " '6ecdf524-7700-4383-a1c6-1e1050f3ab34',\n",
       " 'a3a14066-8a89-49b4-b5b5-22b8e8185523',\n",
       " '9f9d67e2-faa2-481e-aa28-84f692e3068f',\n",
       " '2887d501-8d37-4be4-9bd2-b7b222d5ca20',\n",
       " '5a52590c-b730-4221-bdd3-1517155b54c8',\n",
       " '7bd9f669-98ab-462a-8ba1-3cd764950335',\n",
       " 'f1cb0751-6856-4c50-b61f-f24266695f5f',\n",
       " '2492ac75-ea12-4764-be91-9203466a3bad',\n",
       " 'b8187924-b976-4532-9c29-52d151e7ce72',\n",
       " '691b321c-9d53-44c7-a09a-f5f1c1915877',\n",
       " 'd96bf07a-9ab6-4eae-ba56-cdf53ee307ca',\n",
       " 'ed0b5a90-3a94-473c-a48c-8a62e8e6d1af',\n",
       " 'e6bbcb07-e23a-47d1-8504-3d6323bbbfa1',\n",
       " '1944584f-7bcd-42ea-af06-055c9b544a18',\n",
       " '09d477a1-93d5-44eb-a29d-113e847445d6',\n",
       " '888094c3-3ecd-42b1-983c-a9f85ab4be37',\n",
       " '233d1ac2-62c6-4ec7-8de1-0e3994c7e32b',\n",
       " '35b592a5-d7bb-4eb4-b25b-ef079872571f',\n",
       " 'a7916d2c-c876-4997-a4ed-34d11a6e768e',\n",
       " '168bb5b4-4162-4906-8fee-11284e516322',\n",
       " 'bd0b59c2-d119-4200-8d19-4ec0ba81af9e',\n",
       " '34beebed-2af9-439f-a49e-eba518ffdd43',\n",
       " '459137e4-f635-4549-b9eb-92e67360ea09',\n",
       " 'ab38e212-2e9f-4fbf-b21c-f8bbfd8057aa',\n",
       " 'dfa37e5d-674c-4531-a561-b769d6ca9942',\n",
       " 'ff5969fa-2adb-4d02-a3f3-60f198e74c50',\n",
       " '7b627c49-0223-41eb-9663-8cec6f15fd4b',\n",
       " 'e8fb59a0-4b16-4e9a-9c4d-21e07ef45df5',\n",
       " 'ff960132-0cd9-41cb-b5ce-73a84f3ae5f6',\n",
       " 'd4d69d15-d90b-4d36-85ca-013bf45b9dfd',\n",
       " '5ec4da53-7378-4831-9de1-fef1906044e3',\n",
       " '5b083dad-9263-4ef6-9a69-cc11b31cfb3b',\n",
       " '45e96813-b394-4bbd-8ad3-73e29a19f7e7',\n",
       " '4cd0fd47-43cd-4b2e-9fdc-4315eea41f87',\n",
       " '29048d91-0546-4943-a18c-358cfe1f9723',\n",
       " 'd358cac1-24af-47b2-88ce-19ff5607939a',\n",
       " '354d6afe-2b5d-4688-830c-3f1bd287f118',\n",
       " '7b32f40a-b4aa-45f2-b020-13cee1184c1d',\n",
       " '5e519905-8c62-41bc-ad83-cd12a66e11ff',\n",
       " '111182b2-da2e-4728-a6df-ee43db0ade13',\n",
       " '484d9223-92ba-4802-834f-2e3f83657be8',\n",
       " '8f8d421f-dc7f-45d9-8485-c47c5b0bc605',\n",
       " 'e0d355eb-c9c1-4ec8-abe6-c82e1910d4d9',\n",
       " '0b6946b6-6442-4d41-bbcd-b917c5c91300',\n",
       " 'aadce5ad-d1e2-4ca7-a137-70573d4002f2',\n",
       " 'd501a2ca-88a8-4348-a85c-48238fd3700b',\n",
       " 'b5467aba-d562-4eec-b898-9ddffbd0267e',\n",
       " 'd15f6e33-fb26-4d5e-9df3-01113d0b679c',\n",
       " '27f2c970-e637-4457-98a0-2c9ac7a29d98',\n",
       " 'a9a030a6-b220-4e23-a786-56612fa25406',\n",
       " 'dc925126-c1f6-4166-bcd7-d5bfb2ade618',\n",
       " 'c428d97f-3d49-4b3d-9597-9522caa2b697',\n",
       " 'd76ee9bb-33d2-4c2a-af31-d4d89c0d8978',\n",
       " '0710f726-9bbe-4047-b8c2-e2de4e1dc80b',\n",
       " '70d45fe7-fc82-4fa6-8902-d93e6de01483',\n",
       " 'a16566cf-fcd5-43cf-b2b9-4962220b2808',\n",
       " 'd0d8193e-1cb7-4e11-88ea-9e5a93622fe4',\n",
       " '5ec8e07f-c984-4eff-9244-47425b90f753',\n",
       " 'b975adf4-9dfa-41d0-8326-6f86b375b1aa',\n",
       " '46b9338f-984a-49aa-afb9-3a3c71026d36',\n",
       " '30d39e31-fc77-4cdc-92ae-9460f35d9f1e',\n",
       " '1eab8b3d-c560-4c22-838e-f31ba79407d0',\n",
       " '843a0eec-45dc-43a1-b78f-70505bd24da9',\n",
       " '98f2ebec-9b23-4c97-818c-3dc5d006dd84',\n",
       " '49d850a1-655b-4a74-afcb-ec0666376790',\n",
       " 'f049c995-b59d-45d0-8297-0883157aa4e0',\n",
       " 'f686dc4d-db36-48bf-9f9f-a5f517ebe7f6',\n",
       " 'cda3f7c1-50f3-44e0-bbc2-6a9229be6a23',\n",
       " '9ede550b-9ac3-4437-b4d9-7f402dbb03e0',\n",
       " '90a994a2-cf2e-464b-a13d-a846e4014cac',\n",
       " 'fd146695-9ced-4c1e-823b-7fc10ab693fe',\n",
       " '0c2a5421-15d5-4d46-93b6-fbfdc2d60f69',\n",
       " 'ed6312de-7715-43b9-8da7-ffbea9ee56ea',\n",
       " 'c3d7d1b3-e5bf-471d-bf53-f0519105b6df',\n",
       " 'b6e56b3d-858a-4735-9a97-8db7ebd06b3d',\n",
       " '13f80a87-355a-4628-b7df-4939be3f65bb',\n",
       " '4bc72b21-c2af-4d88-855b-b08415ae1f82',\n",
       " 'aa5f33a9-bb1b-408f-b808-1869fdb27c03',\n",
       " '3ff464de-d0b5-4181-94b8-4f1cdd86024a',\n",
       " '38c24ea1-e08b-45a6-8e56-f51362b4c76c',\n",
       " '1fa8532b-6d69-4684-a830-143af2e02ff0',\n",
       " 'd7185f17-8738-40a3-be67-90a7ade2de65',\n",
       " 'b140dc86-3bbd-45b2-a551-5395d1cf67aa',\n",
       " '9f6ae6eb-50ac-405d-a415-65771e073ab0',\n",
       " 'e562015f-06a4-46f1-9c6c-c489f442d778',\n",
       " '95f999e1-e1ba-4f1d-a140-26eb6a5cc7ea',\n",
       " 'b48b2d7b-084b-4ac6-8b72-de29f9fbbe35',\n",
       " '7af9846d-90fe-42b3-8e32-68aa83bed9bd',\n",
       " '5e57df57-9b66-41c0-afb1-0273529346e4',\n",
       " '90d89f48-e3b1-428c-804e-c8523d1de85c',\n",
       " 'a2e4dca2-f667-49ac-9eb6-b0d4097ca1c4',\n",
       " '48a9337d-d5c1-4c62-bf49-2e4b37d500b4',\n",
       " '53fa7d5a-4569-4877-b391-56f42fca8763',\n",
       " '9a13822f-61e2-4586-82b2-3872b99ce1f3',\n",
       " '9e0e94fb-6b7c-4192-859f-3b08537f850b',\n",
       " '7089000a-405b-4fad-871a-0a5b84c0fe93']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initate a embedding \n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"ibm-granite/granite-embedding-125m-english\")\n",
    "# Initate the vector database with the embedding model and pass the documents\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings_model,\n",
    "    persist_directory=\"./chroma_db\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "vector_store.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af56462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initate the retriever\n",
    "retriever = vector_store.as_retriever(search_type = 'similarity',search_kwargs={'k':4})\n",
    "# retriever.invoke(\"What is agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb85a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "routing_to='websearch'\n",
      "routing_to='doc_retriever'\n"
     ]
    }
   ],
   "source": [
    "# Working with tools\n",
    "class Router(BaseModel):\n",
    "    routing_to: Literal['websearch','doc_retriever'] = Field(description=\"Given a user question choose to route it to web search or a vectorstore.\")\n",
    "llm = ChatGroq(temperature=0, model_name=\"llama3-8b-8192\")\n",
    "structured_llm_router = llm.with_structured_output(Router)\n",
    "system = \"\"\"You are an expert at routing a user question to either a vectorstore or a web search engine.\n",
    "The vectorstore contains documents on the following topics:\n",
    "- AI agents (including types of agent memory)\n",
    "- Prompt engineering\n",
    "- Adversarial attacks\n",
    "\n",
    "If the user question is about any of these topics, route it to 'doc_retriever'.\n",
    "Otherwise, route it to 'websearch'.\n",
    "\n",
    "Respond with one of: 'websearch' or 'doc_retriever' only.\n",
    "\"\"\"\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "question_router = route_prompt | structured_llm_router\n",
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"who is Sharukh Khan?\"}\n",
    "    )\n",
    ")\n",
    "print(question_router.invoke({\"question\": \"What are the types of agent memory?\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d661ee58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grader_or_not='yes'\n"
     ]
    }
   ],
   "source": [
    "# Grading the documennts\n",
    "class DocumentGrader(BaseModel):\n",
    "    grader_or_not: str = Field(description=\"Documents are relevant to the query or not\")\n",
    "\n",
    "llm = ChatGroq(temperature=0, model_name=\"llama3-8b-8192\")\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "structured_llm_doc_grader = llm.with_structured_output(DocumentGrader)\n",
    "\n",
    "grading_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"documents_for_grading {document} User question:{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_grader = grading_prompt | structured_llm_doc_grader\n",
    "\n",
    "question = \"agent memory\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(document_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71165158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, the agent memory in a LLM-powered autonomous agent system consists of two types:\n",
      "\n",
      "1. **Short-term memory**: This type of memory is utilized for in-context learning, which allows the agent to learn from its experiences and adapt to new situations.\n",
      "2. **Long-term memory**: This type of memory enables the agent to retain and recall information over extended periods, often by leveraging an external vector store and fast retrieval. This allows the agent to retain knowledge and skills acquired over time.\n",
      "\n",
      "Additionally, the context mentions that the agent's memory can be compared to the human brain's memory, which has different types such as sensory memory, iconic memory, echoic memory, and haptic memory.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are an assistant. Use the following context to answer the question.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\"\"\")\n",
    "\n",
    "# LLM\n",
    "\n",
    "llm = ChatGroq(temperature=0, model_name=\"llama3-8b-8192\")\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86ac09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HallucinationGrader(not_hallucinated='yes')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for hallucination\n",
    "class HallucinationGrader(BaseModel):\n",
    "    not_hallucinated: str = Field(description=\"Answer is grounded in facts. Must be 'yes' or 'no'.\")\n",
    "llm = ChatGroq(temperature=0, model_name=\"llama3-8b-8192\")\n",
    "structured_llm_halluci_grader = llm.with_structured_output(HallucinationGrader)\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts.\n",
    "Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Context:\\n\\n{document}\\n\\nResponse:\\n\\n{response}\\n\\nIs the response grounded in the context?\"),\n",
    "    ]\n",
    ")\n",
    "hallucination_grader = hallucination_prompt | structured_llm_halluci_grader\n",
    "hallucination_grader.invoke({\"document\": docs, \"response\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5724bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerGrader(graded_answer='no')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grading the answer\n",
    "\n",
    "class AnswerGrader(BaseModel):\n",
    "    graded_answer: str = Field(description=\"Answer is relevant and related to question. Must be 'yes' or 'no'.\")\n",
    "\n",
    "llm = ChatGroq(temperature=0, model_name=\"llama3-8b-8192\")\n",
    "structured_llm_answer_grader = llm.with_structured_output(AnswerGrader)\n",
    "system = \"\"\"You are a grader assessing whether a response answers or addresses the user's question.\n",
    "Give a binary score: 'yes' or 'no'. 'Yes' means the answer is relevant and resolves the question.\"\"\"\n",
    "answer_graded_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Question:\\n\\n{question}\\n\\nResponse:\\n\\n{response}\\n\\nDoes the response answer the question?\"),\n",
    "    ]\n",
    ")\n",
    "answer_grader = answer_graded_prompt | structured_llm_answer_grader\n",
    "answer_grader.invoke({\"question\": question, \"response\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82b14a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What are the key components of an agent's memory?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question_rewriter\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for vectorstore retrieval. Look at the input and You must only return the improved question — no commentary, no explanation with about the underlying semantic intent / meaning.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: {question} Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e348ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    response: str\n",
    "    documents: List[str]\n",
    "    generate_placeholder: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62cc725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state:State):\n",
    "    print(\"started generate\")\n",
    "    llm = ChatGroq(temperature=0, model_name=\"llama3-8b-8192\")\n",
    "    \n",
    "    # context = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "    # prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    # You are an assistant. Use the following context to answer the question.\n",
    "\n",
    "    # Context:\n",
    "    # {context}\n",
    "\n",
    "    # Question:\n",
    "    # {question}\n",
    "\n",
    "    # Answer:\"\"\")\n",
    "    \n",
    "    # llm = ChatGroq(temperature=0, model_name=\"llama3-8b-8192\")\n",
    "    # rag_chain = prompt | llm | StrOutputParser()\n",
    "    response = rag_chain.invoke({'question':state['question'],'context':state['documents']})\n",
    "    print(\"The response of generate function is \", response)\n",
    "    print(\"The document inside the generate\",state['documents'])\n",
    "    print(\"Ended Generate\")\n",
    "    return {\"documents\": state['documents'], \"question\": state['question'], \"response\": response}\n",
    "\n",
    "def grade_documents(state:State):\n",
    "    filtered_documents =[]\n",
    "    for d in state['documents']:\n",
    "        score = document_grader.invoke({\"question\": state['question'], \"document\": state['documents']})\n",
    "        if score.grader_or_not == \"yes\":\n",
    "            filtered_documents.append(d)\n",
    "    return {\"documents\":filtered_documents}\n",
    "    \n",
    "def question_rewrite(state:State):\n",
    "    print(\"Entered the question_rewriter\")\n",
    "    response = question_rewriter.invoke({\"question\":state['question']})\n",
    "    print(\"The question has been rewrited successfully as \",response)\n",
    "    return {'question':response}\n",
    "\n",
    "def check_for_hallucination(state:State):\n",
    "    print(\"Entered Hacculination\")\n",
    "    print(\"The document inside hallucination is\", state['documents'])\n",
    "    print(\"The response inside the hallucination\",state['response'])\n",
    "    score = hallucination_grader.invoke({\"document\":state['documents'], 'response':state['response']})\n",
    "    print(\"The hallucination score is\", score.not_hallucinated )\n",
    "    \n",
    "    if score.not_hallucinated == \"yes\":\n",
    "        print(\"Started answer grader\")\n",
    "        response = answer_grader.invoke({'question':state['question'], 'response':state['response']})\n",
    "        print(\"The response from answer grader\", response.graded_answer)\n",
    "        if response.graded_answer == \"yes\":\n",
    "            print(\"Finished the process\")\n",
    "            return \"finished\"\n",
    "        else:\n",
    "            print(\"changing the query\")\n",
    "            return \"transform_question\"\n",
    "\n",
    "    else:\n",
    "        print(\"Again generation\")\n",
    "        return \"generate\"\n",
    "\n",
    "def decision_to_generate(state:State):\n",
    "    if state['documents']:\n",
    "        return 'generate'\n",
    "    else:\n",
    "        return 'transform_question'\n",
    "\n",
    "def web_search_tool(state:State):\n",
    "    # api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
    "    # wikitool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "    # result = wikitool.invoke({'query': state['question']})\n",
    "    search = DuckDuckGoSearchRun()\n",
    "\n",
    "    result = search.invoke({'query': state['question']})\n",
    "    print(\"The wikitool result\",result)\n",
    "    documents = Document(page_content = result)\n",
    "    return {'documents':documents,} # 'question':state['question']\n",
    "\n",
    "def retrieve(state:State):\n",
    "    print(\"Entered the retriever\")\n",
    "    print(\"The question in the retriever is \",state['question'])\n",
    "    documents = retriever.invoke(state['question'])\n",
    "    return {'documents':documents,} # 'question':state['question']\n",
    "\n",
    "def router(state:State):\n",
    "    result = question_router.invoke({'question':state['question']})\n",
    "    print(\"Reached router\")\n",
    "    if result.routing_to == 'websearch':\n",
    "        print(\"Inside websearch\")\n",
    "        return 'websearch'\n",
    "    else:\n",
    "        print(\"Inside websearch\")\n",
    "        return 'doc_retriever'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0febee",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node('websearch',web_search_tool)\n",
    "graph_builder.add_node('doc_retriever',retrieve)\n",
    "graph_builder.add_node('generate',generate)\n",
    "graph_builder.add_node('transform_question',question_rewrite)\n",
    "graph_builder.add_node('grade_documents',grade_documents)\n",
    "\n",
    "graph_builder.add_conditional_edges(START,router,{\"websearch\": \"websearch\", 'doc_retriever': 'doc_retriever'})\n",
    "graph_builder.add_edge(\"transform_question\", \"doc_retriever\")\n",
    "graph_builder.add_conditional_edges('grade_documents',decision_to_generate,{'generate': 'generate','transform_question':'transform_question'})\n",
    "graph_builder.add_edge(\"doc_retriever\",'grade_documents')\n",
    "graph_builder.add_edge( \"websearch\", 'generate')\n",
    "graph_builder.add_conditional_edges('generate',check_for_hallucination,{\"finished\": END, 'generate': 'generate','transform_question':'transform_question'})\n",
    "# Compile\n",
    "app = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Run\n",
    "# inputs = {\n",
    "#     \"question\": \"Avengers\"\n",
    "# }\n",
    "inputs = {\n",
    "    \"question\": \"Agent Memory\"\n",
    "}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs)\n",
    "pprint(value['response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
